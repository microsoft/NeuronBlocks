{
  "license": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.",
  "tool_version": "1.1.0",
  "model_description": "This model is used for question answer matching task, and it achieved auc: 0.7548 in WikiQACorpus test set.",
  "inputs": {
    "use_cache": true,
    "dataset_type": "classification",
    "data_paths": {
      "train_data_path": "./dataset/WikiQACorpus/WikiQA-train.tsv",
      "valid_data_path": "./dataset/WikiQACorpus/WikiQA-dev.tsv",
      "test_data_path": "./dataset/WikiQACorpus/WikiQA-test.tsv",
      "pre_trained_emb": "./dataset/GloVe/glove.840B.300d.txt"
    },
    "file_with_col_header": true,
    "add_start_end_for_seq": true,
    "file_header": {
      "question_id": 0,
      "question_text": 1,
      "document_id": 2,
      "document_title": 3,
      "passage_id": 4,
      "passage_text": 5,
      "label":  6
    },
    "model_inputs": {
      "question": ["question_text"],
      "passage": ["passage_text"]
    },
    "target": ["label"]
  },
  "outputs":{
    "save_base_dir": "./models/wikiqa_bilstm_attn/",
    "model_name": "model.nb",
    "train_log_name": "train.log",
    "test_log_name": "test.log",
    "predict_log_name": "predict.log",
    "predict_fields": ["prediction"],
    "predict_output_name": "predict.tsv",
    "cache_dir": ".cache.wikiqa/"
  },
  "training_params": {
    "vocabulary": {
      "min_word_frequency": 1
    },
    "optimizer": {
      "name": "Adam",
      "params": {
      }
    },
    "lr_decay": 0.95,
    "minimum_lr": 0.0001,
    "epoch_start_lr_decay": 3,
    "use_gpu": true,
    "batch_size": 30,
    "batch_num_to_show_results": 100,
    "max_epoch": 30,
    "valid_times_per_epoch": 5
  },
  "architecture":[
    {
        "layer": "Embedding",
        "conf": {
          "word": {
            "cols": ["question_text", "passage_text"],
            "dim": 300,
            "fix_weight": true
          }
        }
    },
    {
      "layer_id": "question_dropout",
      "layer": "Dropout",
      "conf": {
          "dropout": 0.2
      },
      "inputs": ["question"]
    },
    {
      "layer_id": "passage_dropout",
      "layer": "Dropout",
      "conf": {
          "dropout": 0.2
      },
      "inputs": ["passage"]
    },
    {
        "layer_id": "question_bilstm",
        "layer": "BiLSTM",
        "conf": {
          "hidden_dim": 128,
          "dropout": 0.2,
          "num_layers": 2
        },
        "inputs": ["question_dropout"]
    },
    {
        "layer_id": "passage_bilstm",
        "layer": "question_bilstm",
        "inputs": ["passage_dropout"]
    },
        {
        "layer_id": "question_attn",
        "layer": "Attention",
        "conf": {
        },
        "inputs": ["question_bilstm","passage_bilstm"]
    },
    {
        "layer_id": "passage_attn",
        "layer": "Attention",
        "conf": {
        },
        "inputs": ["passage_bilstm","question_bilstm"]
    },
    {
        "layer_id": "question_comb",
        "layer": "Combination",
        "conf": {
            "operations": ["origin"]
        },
        "inputs": ["question_bilstm", "question_attn"]
    },
    {
        "layer_id": "passage_comb",
        "layer": "Combination",
        "conf": {
            "operations": ["origin"]
        },
        "inputs": ["passage_bilstm", "passage_attn"]
    },
    {
        "layer_id": "question_bilstm2",
        "layer": "BiLSTM",
        "conf": {
          "hidden_dim": 128,
          "dropout": 0.2,
          "num_layers": 2
        },
        "inputs": ["question_comb"]
    },
    {
        "layer_id": "passage_bilstm2",
        "layer": "BiLSTM",
        "conf": {
          "hidden_dim": 128,
          "dropout": 0.2,
          "num_layers": 2
        },
        "inputs": ["passage_comb"]
    },
    {
        "layer_id": "question_pooling",
        "layer": "Pooling",
        "conf": {
          "pool_axis": 1,
          "pool_type": "max"
        },
        "inputs": ["question_bilstm2"]
    },
    {
        "layer_id": "passage_pooling",
        "layer": "question_pooling",
        "inputs": ["passage_bilstm2"]
    },
    {
        "layer_id": "comb_qp",
        "layer": "Combination",
        "conf": {
            "operations": ["origin", "difference", "dot_multiply"]
        },
        "inputs": ["question_pooling", "passage_pooling"]
    },
    {
        "output_layer_flag": true,
        "layer_id": "output",
        "layer": "Linear",
        "conf": {
          "hidden_dim": [128,2],
          "activation": "PReLU",
          "last_hidden_activation": false,
          "last_hidden_softmax": false
        },
        "inputs": ["comb_qp"]
    }
  ],
  "loss": {
    "losses": [
      {
        "type": "CrossEntropyLoss",
        "conf": {
          "weight": [0.1,0.9],
          "size_average": true
        },
        "inputs": ["output","label"]
      }
    ]
  },
  "metrics": ["auc","accuracy"]
}